{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08cbc127",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import ngrams\n",
    "import nltk\n",
    "import re\n",
    "import string\n",
    "import urllib.request\n",
    "import requests\n",
    "import bs4 as bs\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "from datetime import datetime\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, cross_validate\n",
    "from sklearn.decomposition import PCA,LatentDirichletAllocation, TruncatedSVD\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from textblob import TextBlob,Word"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd55577a",
   "metadata": {},
   "source": [
    "# building a crawler to get insomnia data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d54f20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getlinks(soup):\n",
    "    l = []\n",
    "    for link in soup.find_all('a',class_ = \"bbp-topic-permalink\",href = True):\n",
    "        l.append(link['href'][0:])\n",
    "        \n",
    "    return l\n",
    "\n",
    "def getdate(soup):\n",
    "    l = []\n",
    "    div = soup.find('span', class_ = 'bbp-reply-post-date')\n",
    "    return(div.text)\n",
    "#\n",
    "def getname(soup):\n",
    "    l = []\n",
    "    div = soup.find('a', class_ = 'bbp-author-name') \n",
    "    return([div.text])   \n",
    "#\n",
    "def gettext(soup):\n",
    "    p = soup.find_all('div', class_ = 'bbp-reply-content')\n",
    "    return p[1].text\n",
    "#\n",
    "\n",
    "sitelist = []\n",
    "site = 'https://insomniacoach.com/forums/id/insomnia-help'\n",
    "string = '/page/'\n",
    "hdr = {'User-Agent': 'Mozilla/5.0'}\n",
    "for i in range(1,197): \n",
    "    sitelist.append(site + string + str(i)+'/')\n",
    "\n",
    "dftoappend = pd.DataFrame()\n",
    "df = pd.DataFrame()\n",
    "\n",
    "for sites in sitelist:\n",
    "    print(sites)\n",
    "    request = Request(sites, headers=hdr)\n",
    "    sauce = urllib.request.urlopen(request)\n",
    "    soup = bs.BeautifulSoup(sauce,'html.parser')\n",
    "    links = getlinks(soup)\n",
    "    for link in links:\n",
    "        request1 = Request(link, headers=hdr)\n",
    "        sauce = urllib.request.urlopen(request1)\n",
    "        soup = bs.BeautifulSoup(sauce,'html.parser')\n",
    "        date = getdate(soup)\n",
    "        name = getname(soup)\n",
    "        text = gettext(soup)\n",
    "        d = [{'DATE' : date, 'NAME' : name, 'TEXT' : text, 'STATE' : \"insomnia\"}]\n",
    "        dftoappend = pd.DataFrame(d)\n",
    "        df = df.append(dftoappend,ignore_index = True)\n",
    "df.to_csv('insomnia.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29855f10",
   "metadata": {},
   "source": [
    "# loading the other data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05e22703",
   "metadata": {},
   "outputs": [],
   "source": [
    "anxiety=pd.read_csv('anxiety.csv')\n",
    "depression=pd.read_csv('depression.csv')\n",
    "trauma=pd.read_csv('trauma.csv')\n",
    "suicidal_thoughts=pd.read_csv('suicidal_thoughts.csv')\n",
    "stress=pd.read_csv('stress.csv')\n",
    "neutral=pd.read_csv('neutral.csv')\n",
    "insomnia=pd.read_csv('insomnia.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21114414",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>DATE</th>\n",
       "      <th>NAME</th>\n",
       "      <th>TEXT</th>\n",
       "      <th>STATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>\\n                            \\n              ...</td>\n",
       "      <td>['CMF']</td>\n",
       "      <td>\\nThere is a thread under Depression just like...</td>\n",
       "      <td>anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>\\n                            \\n              ...</td>\n",
       "      <td>['annabay']</td>\n",
       "      <td>\\nhey there, what physical symptoms of anxiety...</td>\n",
       "      <td>anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>\\n                            \\n              ...</td>\n",
       "      <td>['AGrace']</td>\n",
       "      <td>\\nHi Everyone,\\nHere are some ideas for helpin...</td>\n",
       "      <td>anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>\\n                            \\n              ...</td>\n",
       "      <td>['Lind779']</td>\n",
       "      <td>\\nHi everyone,\\nI would love to hear your stor...</td>\n",
       "      <td>anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>\\n                            \\n              ...</td>\n",
       "      <td>['Chris B']</td>\n",
       "      <td>\\nHi everyone, particularly any new members wh...</td>\n",
       "      <td>anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33650</th>\n",
       "      <td>NaN</td>\n",
       "      <td>94448.0</td>\n",
       "      <td>none</td>\n",
       "      <td>['y11611']</td>\n",
       "      <td>They have an alright casino area, food wasn't ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33651</th>\n",
       "      <td>NaN</td>\n",
       "      <td>94449.0</td>\n",
       "      <td>none</td>\n",
       "      <td>['y1234', 'y1235']</td>\n",
       "      <td>We went around lunchtime, but it wasn't very b...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33652</th>\n",
       "      <td>NaN</td>\n",
       "      <td>94450.0</td>\n",
       "      <td>none</td>\n",
       "      <td>['y2418', 'y8084']</td>\n",
       "      <td>We ordered the MTO breakfast with a pancake.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33653</th>\n",
       "      <td>NaN</td>\n",
       "      <td>94452.0</td>\n",
       "      <td>none</td>\n",
       "      <td>['y18958', 'y4005']</td>\n",
       "      <td>The only people in Vegas that aren't predators...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33654</th>\n",
       "      <td>NaN</td>\n",
       "      <td>94456.0</td>\n",
       "      <td>none</td>\n",
       "      <td>['y13964']</td>\n",
       "      <td>From September 2010 visit:\\n\\nDecided to dine ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51411 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0.1  Unnamed: 0  \\\n",
       "0               0.0         0.0   \n",
       "1               1.0         1.0   \n",
       "2               2.0         2.0   \n",
       "3               3.0         3.0   \n",
       "4               4.0         4.0   \n",
       "...             ...         ...   \n",
       "33650           NaN     94448.0   \n",
       "33651           NaN     94449.0   \n",
       "33652           NaN     94450.0   \n",
       "33653           NaN     94452.0   \n",
       "33654           NaN     94456.0   \n",
       "\n",
       "                                                    DATE                 NAME  \\\n",
       "0      \\n                            \\n              ...              ['CMF']   \n",
       "1      \\n                            \\n              ...          ['annabay']   \n",
       "2      \\n                            \\n              ...           ['AGrace']   \n",
       "3      \\n                            \\n              ...          ['Lind779']   \n",
       "4      \\n                            \\n              ...          ['Chris B']   \n",
       "...                                                  ...                  ...   \n",
       "33650                                               none           ['y11611']   \n",
       "33651                                               none   ['y1234', 'y1235']   \n",
       "33652                                               none   ['y2418', 'y8084']   \n",
       "33653                                               none  ['y18958', 'y4005']   \n",
       "33654                                               none           ['y13964']   \n",
       "\n",
       "                                                    TEXT    STATE  \n",
       "0      \\nThere is a thread under Depression just like...  anxiety  \n",
       "1      \\nhey there, what physical symptoms of anxiety...  anxiety  \n",
       "2      \\nHi Everyone,\\nHere are some ideas for helpin...  anxiety  \n",
       "3      \\nHi everyone,\\nI would love to hear your stor...  anxiety  \n",
       "4      \\nHi everyone, particularly any new members wh...  anxiety  \n",
       "...                                                  ...      ...  \n",
       "33650  They have an alright casino area, food wasn't ...  neutral  \n",
       "33651  We went around lunchtime, but it wasn't very b...  neutral  \n",
       "33652       We ordered the MTO breakfast with a pancake.  neutral  \n",
       "33653  The only people in Vegas that aren't predators...  neutral  \n",
       "33654  From September 2010 visit:\\n\\nDecided to dine ...  neutral  \n",
       "\n",
       "[51411 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset=pd.concat([anxiety,depression,trauma,suicidal_thoughts,stress,insomnia,neutral])\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964d79ee",
   "metadata": {},
   "source": [
    "# extracting basic features\n",
    "First, we will extract all the feature we can from the uncleaned data(description below) we will count the words, the characters,the numerics, the number of spaces, whether they tag something, the number of stopwords(description below), and the lexical divercity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47888b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_word(sentence):\n",
    "    words = sentence.split()\n",
    "    return (sum(len(word) for word in words)/len([words]))\n",
    "\n",
    "def pipeline(train1, whatstop):\n",
    "    train1['LINE_NUM'] = train1['TEXT'].apply(lambda x: str(x).count('\\n') - 2)\n",
    "    train1['WORD_COUNT'] = train1['TEXT'].apply(lambda x: len(str(x).split(\" \")))\n",
    "    train1['CHAR_COUNT'] = train1['TEXT'].str.len() ## this also includes spaces\n",
    "    train1['TEXT'] = train1['TEXT'].str.replace(r'\\n',\" \")\n",
    "    train1['TEXT'] = train1['TEXT'].str.replace(r'\\s+',' ')\n",
    "    train1['TAG'] = train1['TEXT'].str.contains('@')\n",
    "    train1['STOPWORDS'] = train1['TEXT'].apply(lambda x: len([x for x in str(x).split() if x in whatstop]))\n",
    "    train1['HASHTAGS'] = train1['TEXT'].apply(lambda x: len([x for x in str(x).split() if x.startswith('#')]))\n",
    "    train1['UPPER'] = train1['TEXT'].apply(lambda x: len([x for x in str(x).split() if x.isupper()]))\n",
    "    train1['NUMERICS'] = train1['TEXT'].apply(lambda x: len([x for x in str(x).split() if x.isdigit()]))\n",
    "    #train1['AVG_WORDS_LEN'] = train1['TEXT'].apply(lambda x: avg_word(str(x)))\n",
    "    train1['AVG_WORDS_LEN'] = train1['CHAR_COUNT'] / train1['WORD_COUNT'] # including spaces\n",
    "    #lexical divercity\n",
    "    train1['LEXICAL_DIVER'] = train1['TEXT'].apply(lambda x: len(str(x)) / len(set(str(x))))\n",
    "    return train1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe041b5",
   "metadata": {},
   "source": [
    "in order to count the stopwords and use it afterwards to clean the data, we will use a set from nltk.corpus, and add more words manually, this stage is importent and we will get to this frequently, in order to clean the text better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1fc00969",
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_stopwords = \"you that him to it her there etc know want one hey hi yep well really hello a like don't about above after again against all am an and any are aren't as at be because been before being below between both but by can't cannot could couldn't did didn't do does doesn't doing don't down during each few for from further had hadn't has hasn't have haven't having he he'd he'll he's her here here's hers herself him himself his how how's i i'd i'll i'm i've if in into is isn't it it's its itself let's me more most mustn't my myself no nor not of off on once only or other oughtour ours ourselves out over own same shan't she she'd she'll she's should shouldn't so some such than that that's the their theirs them themselves then there there's these they they'd they'll they're they've this those through to too under until up very was wasn't we we'd we'll we're we've were weren't what what's when when's where where's which while who who's whom why why's with won't would wouldn't you you'd you'll you're you've your yours yourself yourselves\"\n",
    "removing_words = 'beyondblue beyond blue tony wk tony geoff neil depression anxiety trauma insomnia suicidal thoughts stress insomniacoach '\n",
    "englishstop = stopwords.words(\"english\")\n",
    "englishstop += additional_stopwords.split()\n",
    "englishstop += removing_words.split()\n",
    "nopunc = re.sub(\"'\",'',additional_stopwords)\n",
    "englishstop += nopunc.split()\n",
    "englishstop = set(englishstop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5096ec70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\waels\\AppData\\Local\\Temp/ipykernel_9476/735892834.py:9: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  train1['TEXT'] = train1['TEXT'].str.replace(r'\\n',\" \")\n",
      "C:\\Users\\waels\\AppData\\Local\\Temp/ipykernel_9476/735892834.py:10: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  train1['TEXT'] = train1['TEXT'].str.replace(r'\\s+',' ')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>DATE</th>\n",
       "      <th>NAME</th>\n",
       "      <th>TEXT</th>\n",
       "      <th>STATE</th>\n",
       "      <th>LINE_NUM</th>\n",
       "      <th>WORD_COUNT</th>\n",
       "      <th>CHAR_COUNT</th>\n",
       "      <th>TAG</th>\n",
       "      <th>STOPWORDS</th>\n",
       "      <th>HASHTAGS</th>\n",
       "      <th>UPPER</th>\n",
       "      <th>NUMERICS</th>\n",
       "      <th>AVG_WORDS_LEN</th>\n",
       "      <th>LEXICAL_DIVER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>\\n                            \\n              ...</td>\n",
       "      <td>['CMF']</td>\n",
       "      <td>There is a thread under Depression just like ...</td>\n",
       "      <td>anxiety</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>116.0</td>\n",
       "      <td>False</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>4.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>\\n                            \\n              ...</td>\n",
       "      <td>['annabay']</td>\n",
       "      <td>hey there, what physical symptoms of anxiety ...</td>\n",
       "      <td>anxiety</td>\n",
       "      <td>2</td>\n",
       "      <td>61</td>\n",
       "      <td>335.0</td>\n",
       "      <td>False</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5.491803</td>\n",
       "      <td>11.448276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>\\n                            \\n              ...</td>\n",
       "      <td>['AGrace']</td>\n",
       "      <td>Hi Everyone, Here are some ideas for helping ...</td>\n",
       "      <td>anxiety</td>\n",
       "      <td>18</td>\n",
       "      <td>151</td>\n",
       "      <td>957.0</td>\n",
       "      <td>False</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6.337748</td>\n",
       "      <td>19.770833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>\\n                            \\n              ...</td>\n",
       "      <td>['Lind779']</td>\n",
       "      <td>Hi everyone, I would love to hear your storie...</td>\n",
       "      <td>anxiety</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>283.0</td>\n",
       "      <td>False</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5.660000</td>\n",
       "      <td>9.129032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>\\n                            \\n              ...</td>\n",
       "      <td>['Chris B']</td>\n",
       "      <td>Hi everyone, particularly any new members who...</td>\n",
       "      <td>anxiety</td>\n",
       "      <td>16</td>\n",
       "      <td>306</td>\n",
       "      <td>1707.0</td>\n",
       "      <td>False</td>\n",
       "      <td>151</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5.578431</td>\n",
       "      <td>40.380952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33650</th>\n",
       "      <td>NaN</td>\n",
       "      <td>94448.0</td>\n",
       "      <td>none</td>\n",
       "      <td>['y11611']</td>\n",
       "      <td>They have an alright casino area, food wasn't ...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>-2</td>\n",
       "      <td>14</td>\n",
       "      <td>77.0</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>3.347826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33651</th>\n",
       "      <td>NaN</td>\n",
       "      <td>94449.0</td>\n",
       "      <td>none</td>\n",
       "      <td>['y1234', 'y1235']</td>\n",
       "      <td>We went around lunchtime, but it wasn't very b...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>-2</td>\n",
       "      <td>9</td>\n",
       "      <td>50.0</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.555556</td>\n",
       "      <td>2.173913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33652</th>\n",
       "      <td>NaN</td>\n",
       "      <td>94450.0</td>\n",
       "      <td>none</td>\n",
       "      <td>['y2418', 'y8084']</td>\n",
       "      <td>We ordered the MTO breakfast with a pancake.</td>\n",
       "      <td>neutral</td>\n",
       "      <td>-2</td>\n",
       "      <td>8</td>\n",
       "      <td>44.0</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33653</th>\n",
       "      <td>NaN</td>\n",
       "      <td>94452.0</td>\n",
       "      <td>none</td>\n",
       "      <td>['y18958', 'y4005']</td>\n",
       "      <td>The only people in Vegas that aren't predators...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>-2</td>\n",
       "      <td>12</td>\n",
       "      <td>66.0</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>3.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33654</th>\n",
       "      <td>NaN</td>\n",
       "      <td>94456.0</td>\n",
       "      <td>none</td>\n",
       "      <td>['y13964']</td>\n",
       "      <td>From September 2010 visit: Decided to dine her...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>118.0</td>\n",
       "      <td>False</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.210526</td>\n",
       "      <td>4.034483</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51411 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0.1  Unnamed: 0  \\\n",
       "0               0.0         0.0   \n",
       "1               1.0         1.0   \n",
       "2               2.0         2.0   \n",
       "3               3.0         3.0   \n",
       "4               4.0         4.0   \n",
       "...             ...         ...   \n",
       "33650           NaN     94448.0   \n",
       "33651           NaN     94449.0   \n",
       "33652           NaN     94450.0   \n",
       "33653           NaN     94452.0   \n",
       "33654           NaN     94456.0   \n",
       "\n",
       "                                                    DATE                 NAME  \\\n",
       "0      \\n                            \\n              ...              ['CMF']   \n",
       "1      \\n                            \\n              ...          ['annabay']   \n",
       "2      \\n                            \\n              ...           ['AGrace']   \n",
       "3      \\n                            \\n              ...          ['Lind779']   \n",
       "4      \\n                            \\n              ...          ['Chris B']   \n",
       "...                                                  ...                  ...   \n",
       "33650                                               none           ['y11611']   \n",
       "33651                                               none   ['y1234', 'y1235']   \n",
       "33652                                               none   ['y2418', 'y8084']   \n",
       "33653                                               none  ['y18958', 'y4005']   \n",
       "33654                                               none           ['y13964']   \n",
       "\n",
       "                                                    TEXT    STATE  LINE_NUM  \\\n",
       "0       There is a thread under Depression just like ...  anxiety         2   \n",
       "1       hey there, what physical symptoms of anxiety ...  anxiety         2   \n",
       "2       Hi Everyone, Here are some ideas for helping ...  anxiety        18   \n",
       "3       Hi everyone, I would love to hear your storie...  anxiety         2   \n",
       "4       Hi everyone, particularly any new members who...  anxiety        16   \n",
       "...                                                  ...      ...       ...   \n",
       "33650  They have an alright casino area, food wasn't ...  neutral        -2   \n",
       "33651  We went around lunchtime, but it wasn't very b...  neutral        -2   \n",
       "33652       We ordered the MTO breakfast with a pancake.  neutral        -2   \n",
       "33653  The only people in Vegas that aren't predators...  neutral        -2   \n",
       "33654  From September 2010 visit: Decided to dine her...  neutral         0   \n",
       "\n",
       "       WORD_COUNT  CHAR_COUNT    TAG  STOPWORDS  HASHTAGS  UPPER  NUMERICS  \\\n",
       "0              20       116.0  False         11         0      1         0   \n",
       "1              61       335.0  False         28         0      2         0   \n",
       "2             151       957.0  False         59         0      1         0   \n",
       "3              50       283.0  False         26         0      2         0   \n",
       "4             306      1707.0  False        151         0      3         0   \n",
       "...           ...         ...    ...        ...       ...    ...       ...   \n",
       "33650          14        77.0  False          6         0      0         0   \n",
       "33651           9        50.0  False          4         0      0         0   \n",
       "33652           8        44.0  False          3         0      1         0   \n",
       "33653          12        66.0  False          6         0      0         0   \n",
       "33654          19       118.0  False          9         0      0         1   \n",
       "\n",
       "       AVG_WORDS_LEN  LEXICAL_DIVER  \n",
       "0           5.800000       4.142857  \n",
       "1           5.491803      11.448276  \n",
       "2           6.337748      19.770833  \n",
       "3           5.660000       9.129032  \n",
       "4           5.578431      40.380952  \n",
       "...              ...            ...  \n",
       "33650       5.500000       3.347826  \n",
       "33651       5.555556       2.173913  \n",
       "33652       5.500000       2.000000  \n",
       "33653       5.500000       3.142857  \n",
       "33654       6.210526       4.034483  \n",
       "\n",
       "[51411 rows x 16 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#getting the basic feature extraction from the depressed and undepressed posts\n",
    "english = pipeline(dataset,englishstop)\n",
    "english"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2174bb5a",
   "metadata": {},
   "source": [
    "# cleaning the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "407c5fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanpipe(train1,whatstop):\n",
    "    train1['DATE'] = train1['DATE'].str.replace('[\\n\\t\\t\\t]','')\n",
    "    train1['DATE'] = train1['DATE'].str.strip()\n",
    "    train1['WORKING_TEXT'] = train1['TEXT'].apply(lambda x: \" \".join(x.lower() for x in str(x).split()))\n",
    "    train1['WORKING_TEXT'] = train1['WORKING_TEXT'].str.replace(r'\\d+',' ')\n",
    "    train1['WORKING_TEXT'] = train1['WORKING_TEXT'].str.replace(r'[^\\w\\s]',' ')\n",
    "    train1['WORKING_TEXT'] = train1['WORKING_TEXT'].str.replace(r'\\s+',' ')\n",
    "    train1['WORKING_TEXT'] = train1['WORKING_TEXT'].apply(lambda x:\" \".join(x for x in x.split() if (x not in whatstop)))\n",
    "   \n",
    "    train1['WORKING_TEXT'] = train1['WORKING_TEXT'].apply(lambda x: \" \".join(x for x in x.split() if not(x.startswith('www'))))\n",
    "    train1['WORKING_TEXT'] = train1['WORKING_TEXT'].apply(lambda x: \" \".join(x for x in x.split() if not(x.startswith('http'))))                \n",
    "    train1['WORKING_TEXT'] = train1['WORKING_TEXT'].apply(lambda x: \" \".join(x for x in x.split() if not(len(x)< 2)))                \n",
    "\n",
    "    \n",
    "    train1.drop(train1[train1['WORD_COUNT'] < 8].index,inplace = True)\n",
    "    \n",
    "  \n",
    "    \n",
    "    train1 = train1.drop_duplicates(subset = 'WORKING_TEXT')\n",
    "    return train1\n",
    "\n",
    "\n",
    "##remove freq word function\n",
    "def freqremovel(train1, freq):\n",
    "    train1['WORKING_TEXT'] = train1['WORKING_TEXT'].apply(lambda x: \" \".join(x for x in x.split() if x in freq))\n",
    "    return train1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4493e646",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\waels\\AppData\\Local\\Temp/ipykernel_9476/4159192840.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  train1['DATE'] = train1['DATE'].str.replace('[\\n\\t\\t\\t]','')\n",
      "C:\\Users\\waels\\AppData\\Local\\Temp/ipykernel_9476/4159192840.py:5: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  train1['WORKING_TEXT'] = train1['WORKING_TEXT'].str.replace(r'\\d+',' ')\n",
      "C:\\Users\\waels\\AppData\\Local\\Temp/ipykernel_9476/4159192840.py:6: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  train1['WORKING_TEXT'] = train1['WORKING_TEXT'].str.replace(r'[^\\w\\s]',' ')\n",
      "C:\\Users\\waels\\AppData\\Local\\Temp/ipykernel_9476/4159192840.py:7: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  train1['WORKING_TEXT'] = train1['WORKING_TEXT'].str.replace(r'\\s+',' ')\n"
     ]
    }
   ],
   "source": [
    "newenglish = cleanpipe(english,englishstop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9da11123",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\waels\\AppData\\Local\\Temp/ipykernel_9476/2158371470.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  newenglish.drop(columns = ['Unnamed: 0'],inplace = True)\n",
      "C:\\Users\\waels\\AppData\\Local\\Temp/ipykernel_9476/2158371470.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  newenglish.drop(columns = ['Unnamed: 0.1'],inplace = True)\n"
     ]
    }
   ],
   "source": [
    "newenglish.drop(columns = ['Unnamed: 0'],inplace = True)\n",
    "newenglish.drop(columns = ['Unnamed: 0.1'],inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3a4cdc30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>NAME</th>\n",
       "      <th>TEXT</th>\n",
       "      <th>STATE</th>\n",
       "      <th>LINE_NUM</th>\n",
       "      <th>WORD_COUNT</th>\n",
       "      <th>CHAR_COUNT</th>\n",
       "      <th>TAG</th>\n",
       "      <th>STOPWORDS</th>\n",
       "      <th>HASHTAGS</th>\n",
       "      <th>UPPER</th>\n",
       "      <th>NUMERICS</th>\n",
       "      <th>AVG_WORDS_LEN</th>\n",
       "      <th>LEXICAL_DIVER</th>\n",
       "      <th>WORKING_TEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12 June 2016</td>\n",
       "      <td>['CMF']</td>\n",
       "      <td>There is a thread under Depression just like ...</td>\n",
       "      <td>anxiety</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>116.0</td>\n",
       "      <td>False</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>4.142857</td>\n",
       "      <td>thread thought start word attacking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>15 March 2022</td>\n",
       "      <td>['sparrowhawk']</td>\n",
       "      <td>Hi everyone. I have recently been diagnosed w...</td>\n",
       "      <td>anxiety</td>\n",
       "      <td>8</td>\n",
       "      <td>410</td>\n",
       "      <td>2213.0</td>\n",
       "      <td>False</td>\n",
       "      <td>205</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>5.397561</td>\n",
       "      <td>56.589744</td>\n",
       "      <td>everyone recently diagnosed anorexia recovery ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>15 March 2022</td>\n",
       "      <td>['Trixiebell99']</td>\n",
       "      <td>Hello, I am currently feeling very overwhelme...</td>\n",
       "      <td>anxiety</td>\n",
       "      <td>9</td>\n",
       "      <td>463</td>\n",
       "      <td>2429.0</td>\n",
       "      <td>False</td>\n",
       "      <td>219</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>5.246220</td>\n",
       "      <td>46.500000</td>\n",
       "      <td>currently feeling overwhelmed constantly feel ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>17 March 2022</td>\n",
       "      <td>['Towers_chris9009']</td>\n",
       "      <td>So this week have been working from home due ...</td>\n",
       "      <td>anxiety</td>\n",
       "      <td>0</td>\n",
       "      <td>158</td>\n",
       "      <td>867.0</td>\n",
       "      <td>False</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>5.487342</td>\n",
       "      <td>19.659091</td>\n",
       "      <td>week working home due covid levels last pretty...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>16 March 2022</td>\n",
       "      <td>['Apricit@@123']</td>\n",
       "      <td>Does anyone else get anxiety around taking me...</td>\n",
       "      <td>anxiety</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>149.0</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6.208333</td>\n",
       "      <td>5.653846</td>\n",
       "      <td>anyone else get around taking medication massi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33650</th>\n",
       "      <td>none</td>\n",
       "      <td>['y11611']</td>\n",
       "      <td>They have an alright casino area, food wasn't ...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>-2</td>\n",
       "      <td>14</td>\n",
       "      <td>77.0</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>3.347826</td>\n",
       "      <td>alright casino area food great rooms clean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33651</th>\n",
       "      <td>none</td>\n",
       "      <td>['y1234', 'y1235']</td>\n",
       "      <td>We went around lunchtime, but it wasn't very b...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>-2</td>\n",
       "      <td>9</td>\n",
       "      <td>50.0</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.555556</td>\n",
       "      <td>2.173913</td>\n",
       "      <td>went around lunchtime busy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33652</th>\n",
       "      <td>none</td>\n",
       "      <td>['y2418', 'y8084']</td>\n",
       "      <td>We ordered the MTO breakfast with a pancake.</td>\n",
       "      <td>neutral</td>\n",
       "      <td>-2</td>\n",
       "      <td>8</td>\n",
       "      <td>44.0</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>ordered mto breakfast pancake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33653</th>\n",
       "      <td>none</td>\n",
       "      <td>['y18958', 'y4005']</td>\n",
       "      <td>The only people in Vegas that aren't predators...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>-2</td>\n",
       "      <td>12</td>\n",
       "      <td>66.0</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>3.142857</td>\n",
       "      <td>people vegas predators moving game</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33654</th>\n",
       "      <td>none</td>\n",
       "      <td>['y13964']</td>\n",
       "      <td>From September 2010 visit: Decided to dine her...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>118.0</td>\n",
       "      <td>False</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.210526</td>\n",
       "      <td>4.034483</td>\n",
       "      <td>september visit decided dine spontaneously boy...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33783 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                DATE                  NAME  \\\n",
       "0       12 June 2016               ['CMF']   \n",
       "7      15 March 2022       ['sparrowhawk']   \n",
       "8      15 March 2022      ['Trixiebell99']   \n",
       "9      17 March 2022  ['Towers_chris9009']   \n",
       "10     16 March 2022      ['Apricit@@123']   \n",
       "...              ...                   ...   \n",
       "33650           none            ['y11611']   \n",
       "33651           none    ['y1234', 'y1235']   \n",
       "33652           none    ['y2418', 'y8084']   \n",
       "33653           none   ['y18958', 'y4005']   \n",
       "33654           none            ['y13964']   \n",
       "\n",
       "                                                    TEXT    STATE  LINE_NUM  \\\n",
       "0       There is a thread under Depression just like ...  anxiety         2   \n",
       "7       Hi everyone. I have recently been diagnosed w...  anxiety         8   \n",
       "8       Hello, I am currently feeling very overwhelme...  anxiety         9   \n",
       "9       So this week have been working from home due ...  anxiety         0   \n",
       "10      Does anyone else get anxiety around taking me...  anxiety         2   \n",
       "...                                                  ...      ...       ...   \n",
       "33650  They have an alright casino area, food wasn't ...  neutral        -2   \n",
       "33651  We went around lunchtime, but it wasn't very b...  neutral        -2   \n",
       "33652       We ordered the MTO breakfast with a pancake.  neutral        -2   \n",
       "33653  The only people in Vegas that aren't predators...  neutral        -2   \n",
       "33654  From September 2010 visit: Decided to dine her...  neutral         0   \n",
       "\n",
       "       WORD_COUNT  CHAR_COUNT    TAG  STOPWORDS  HASHTAGS  UPPER  NUMERICS  \\\n",
       "0              20       116.0  False         11         0      1         0   \n",
       "7             410      2213.0  False        205         0     19         0   \n",
       "8             463      2429.0  False        219         0     35         0   \n",
       "9             158       867.0  False         65         0     13         0   \n",
       "10             24       149.0  False          6         0      1         0   \n",
       "...           ...         ...    ...        ...       ...    ...       ...   \n",
       "33650          14        77.0  False          6         0      0         0   \n",
       "33651           9        50.0  False          4         0      0         0   \n",
       "33652           8        44.0  False          3         0      1         0   \n",
       "33653          12        66.0  False          6         0      0         0   \n",
       "33654          19       118.0  False          9         0      0         1   \n",
       "\n",
       "       AVG_WORDS_LEN  LEXICAL_DIVER  \\\n",
       "0           5.800000       4.142857   \n",
       "7           5.397561      56.589744   \n",
       "8           5.246220      46.500000   \n",
       "9           5.487342      19.659091   \n",
       "10          6.208333       5.653846   \n",
       "...              ...            ...   \n",
       "33650       5.500000       3.347826   \n",
       "33651       5.555556       2.173913   \n",
       "33652       5.500000       2.000000   \n",
       "33653       5.500000       3.142857   \n",
       "33654       6.210526       4.034483   \n",
       "\n",
       "                                            WORKING_TEXT  \n",
       "0                    thread thought start word attacking  \n",
       "7      everyone recently diagnosed anorexia recovery ...  \n",
       "8      currently feeling overwhelmed constantly feel ...  \n",
       "9      week working home due covid levels last pretty...  \n",
       "10     anyone else get around taking medication massi...  \n",
       "...                                                  ...  \n",
       "33650         alright casino area food great rooms clean  \n",
       "33651                         went around lunchtime busy  \n",
       "33652                      ordered mto breakfast pancake  \n",
       "33653                 people vegas predators moving game  \n",
       "33654  september visit decided dine spontaneously boy...  \n",
       "\n",
       "[33783 rows x 15 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newenglish"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d359708",
   "metadata": {},
   "source": [
    "# frequent word removel and word cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e494f56e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\waels\\AppData\\Local\\Temp/ipykernel_9476/4159192840.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train1['WORKING_TEXT'] = train1['WORKING_TEXT'].apply(lambda x: \" \".join(x for x in x.split() if x in freq))\n"
     ]
    }
   ],
   "source": [
    "englishfreq = pd.Series(' '.join(newenglish['WORKING_TEXT']).split()).value_counts()[220:-600]\n",
    "newenglish = freqremovel(newenglish,englishfreq)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aefc5b23",
   "metadata": {},
   "source": [
    "# Topic modeling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e0af60ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow = CountVectorizer()\n",
    "A = bow.fit_transform(newenglish['WORKING_TEXT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "58f82238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8370477828527154\n",
      "0.8496871107391787\n",
      "0.675458273167376\n"
     ]
    }
   ],
   "source": [
    "clfs = [SVC(kernel='rbf',C=40),MultinomialNB(),KNeighborsClassifier(n_neighbors=7)]\n",
    "for clf in clfs:\n",
    "    scores=cross_validate(clf,A, newenglish['STATE'],cv=10)\n",
    "    print(np.mean(scores[\"test_score\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b305d1aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model score and confusion matrix\n",
      "0.8487494450199793\n",
      "[[ 642  197    9   10    0    0   18]\n",
      " [ 128  559   10   12    0    0   14]\n",
      " [  58   19  285    9    0    1    1]\n",
      " [ 157   93   17 4114    1    2   14]\n",
      " [   3    2    0    1    0    0    2]\n",
      " [  18   63    0    0    0    0    9]\n",
      " [  55   88    7    3    0    1  135]]\n"
     ]
    }
   ],
   "source": [
    "XTrain, XTest, yTrain, yTest = train_test_split(A, newenglish['STATE'], random_state=1, test_size=0.2)\n",
    "\n",
    "model = MultinomialNB()\n",
    "model.fit(XTrain,yTrain)\n",
    "yPred = model.predict(XTest)\n",
    "\n",
    "print('model score and confusion matrix')\n",
    "print(model.score(XTest,yTest))\n",
    "print(confusion_matrix(yTest, yPred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ad0e3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
